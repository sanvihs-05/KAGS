# enhanced_verification.py
import json
import numpy as np
import pickle
from pathlib import Path
from collections import Counter

def analyze_enhanced_multimodal_rag_store(rag_store_path):
    """Enhanced analysis of the multimodal RAG store generated by vector_store.py"""
    rag_path = Path(rag_store_path)
    
    print("üîç Enhanced Multimodal RAG Store Analysis:")
    print("=" * 60)
    
    analysis_results = {
        'embedding_files': {},
        'metadata_analysis': {},
        'store_files_analysis': {},
        'multimodal_capabilities': {}
    }
    
    # 1. Analyze all embedding files
    embedding_files = [
        ("composite_embeddings.npy", "Multi-modal composite embeddings"),
        ("text_embeddings.npy", "Text-only embeddings"),
        ("spatial_embeddings.npy", "Spatial relationship embeddings"),
        ("visual_embeddings.npy", "CLIP visual embeddings"),
        ("architectural_embeddings.npy", "Domain-specific architectural embeddings")
    ]
    
    for file_name, description in embedding_files:
        file_path = rag_path / file_name
        if file_path.exists():
            embeddings = np.load(file_path)
            size_mb = file_path.stat().st_size / 1024 / 1024
            print(f"‚úÖ {description}: {embeddings.shape} ({size_mb:.1f} MB)")
            
            analysis_results['embedding_files'][file_name] = {
                'shape': embeddings.shape,
                'size_mb': size_mb,
                'exists': True,
                'description': description
            }
            
            # Sample analysis
            if embeddings.size > 0:
                print(f"   Sample embedding norm: {np.linalg.norm(embeddings[0]):.3f}")
                print(f"   Mean embedding norm: {np.mean([np.linalg.norm(emb) for emb in embeddings[:100]]):.3f}")
        else:
            print(f"‚ùå {description} not found")
            analysis_results['embedding_files'][file_name] = {'exists': False}
    
    # 2. Analyze consolidated metadata
    metadata_path = rag_path / "consolidated_metadata.json"
    if metadata_path.exists():
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        print(f"\n‚úÖ Consolidated metadata: {len(metadata)} annotations")
        
        # Analyze metadata structure
        if metadata:
            sample_annotation = metadata[0]
            print(f"   Sample annotation keys: {list(sample_annotation.keys())}")
            
            # Room type distribution
            room_types = [ann.get('room_type') for ann in metadata if ann.get('room_type')]
            room_type_dist = Counter(room_types)
            print(f"   Room types found: {len(room_type_dist)} unique types")
            print(f"   Top 5 room types: {room_type_dist.most_common(5)}")
            
            # Function distribution
            functions = [ann.get('function') for ann in metadata if ann.get('function')]
            function_dist = Counter(functions)
            print(f"   Functions found: {len(function_dist)} unique functions")
            
            # Visual features presence
            has_visual = sum(1 for ann in metadata if ann.get('has_visual_features', False))
            print(f"   Annotations with visual features: {has_visual}/{len(metadata)} ({has_visual/len(metadata)*100:.1f}%)")
            
            analysis_results['metadata_analysis'] = {
                'total_annotations': len(metadata),
                'room_type_distribution': dict(room_type_dist.most_common(10)),
                'function_distribution': dict(function_dist.most_common(10)),
                'visual_features_coverage': has_visual/len(metadata),
                'sample_keys': list(sample_annotation.keys())
            }
    
    # 3. Analyze individual stores
    stores_dir = rag_path / "stores"
    if stores_dir.exists():
        store_files = list(stores_dir.glob("*.pkl"))
        print(f"\n‚úÖ Individual stores: {len(store_files)} files")
        
        # Check if model.pkl exists and analyze it
        model_path = stores_dir / "model.pkl"
        if model_path.exists():
            try:
                with open(model_path, 'rb') as f:
                    model_content = pickle.load(f)
                print(f"‚úÖ model.pkl found: {type(model_content)}")
                
                # Check if it's a sentence transformer
                if hasattr(model_content, 'encode'):
                    test_embedding = model_content.encode("test bedroom")
                    print(f"   Model embedding dimension: {len(test_embedding)}")
                    analysis_results['multimodal_capabilities']['custom_model'] = {
                        'exists': True,
                        'type': str(type(model_content)),
                        'embedding_dim': len(test_embedding)
                    }
                elif isinstance(model_content, dict):
                    print(f"   Model dict keys: {list(model_content.keys())}")
                    
            except Exception as e:
                print(f"‚ùå Error loading model.pkl: {e}")
        
        # Analyze a sample store file
        if store_files:
            sample_store = store_files[0]
            try:
                with open(sample_store, 'rb') as f:
                    store_data = pickle.load(f)
                print(f"‚úÖ Sample store analysis: {sample_store.name}")
                print(f"   Store type: {type(store_data)}")
                if hasattr(store_data, 'annotations'):
                    print(f"   Annotations count: {len(store_data.annotations)}")
                if hasattr(store_data, 'composite_embedding_matrix'):
                    if store_data.composite_embedding_matrix is not None:
                        print(f"   Composite embeddings: {store_data.composite_embedding_matrix.shape}")
            except Exception as e:
                print(f"‚ùå Error loading sample store: {e}")
        
        analysis_results['store_files_analysis'] = {
            'count': len(store_files),
            'has_model_pkl': model_path.exists()
        }
    
    # 4. Plan mapping analysis
    plan_mapping_path = rag_path / "plan_mapping.json"
    if plan_mapping_path.exists():
        with open(plan_mapping_path, 'r') as f:
            plan_mapping = json.load(f)
        print(f"\n‚úÖ Plan mapping: {len(plan_mapping)} entries")
        
        # Show sample plan IDs
        plan_ids = set(plan_mapping.values())
        print(f"   Unique plans: {len(plan_ids)}")
        print(f"   Sample plan IDs: {list(plan_ids)[:5]}")
    
    # 5. Multimodal capability assessment
    print(f"\nüéØ Multimodal Capabilities Assessment:")
    print("-" * 40)
    
    has_composite = analysis_results['embedding_files'].get('composite_embeddings.npy', {}).get('exists', False)
    has_visual = analysis_results['embedding_files'].get('visual_embeddings.npy', {}).get('exists', False)
    has_spatial = analysis_results['embedding_files'].get('spatial_embeddings.npy', {}).get('exists', False)
    has_architectural = analysis_results['embedding_files'].get('architectural_embeddings.npy', {}).get('exists', False)
    
    capabilities = {
        'text_processing': True,  # Always available
        'visual_processing': has_visual,
        'spatial_processing': has_spatial,
        'architectural_domain': has_architectural,
        'multimodal_fusion': has_composite
    }
    
    for capability, available in capabilities.items():
        status = "‚úÖ" if available else "‚ùå"
        print(f"{status} {capability.replace('_', ' ').title()}")
    
    analysis_results['multimodal_capabilities'].update(capabilities)
    
    return analysis_results

if __name__ == "__main__":
    # Run the analysis
    results = analyze_enhanced_multimodal_rag_store("enhanced_multimodal_rag_store")
    
    print(f"\nüìä Summary Report:")
    print("=" * 40)
    total_embeddings = sum(1 for f in results['embedding_files'].values() if f.get('exists'))
    print(f"Embedding files found: {total_embeddings}/5")
    
    if 'metadata_analysis' in results:
        print(f"Total annotations: {results['metadata_analysis']['total_annotations']}")
        print(f"Visual coverage: {results['metadata_analysis']['visual_features_coverage']:.1%}")
    
    multimodal_score = sum(results['multimodal_capabilities'].values()) / len(results['multimodal_capabilities'])
    print(f"Multimodal capability score: {multimodal_score:.1%}")
